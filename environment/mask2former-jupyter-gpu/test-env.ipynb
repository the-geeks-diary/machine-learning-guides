{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('Mask2Former'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "import polars as pl\n",
    "import sklearn as sklearn\n",
    "import scipy as scipy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch as pytorch\n",
    "import cv2 as opencv\n",
    "print(f\"Polars Version: {pl.__version__}\")\n",
    "print(f\"scikit-learn Version: {sklearn.__version__}\")\n",
    "print(f\"scipy Version: {scipy.__version__}\")\n",
    "print(f\"pandas Version: {pd.__version__}\")\n",
    "print(f\"matplotlib Version: {matplotlib.__version__}\")\n",
    "print(f\"PyTorch Version: {pytorch.__version__}\")\n",
    "print(f\"OpenCV Version: {opencv.__version__}\")\n",
    "gpu = pytorch.cuda.is_available()\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "setup_logger(name=\"mask2former\")\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "coco_metadata = MetadataCatalog.get(\"coco_2017_val_panoptic\")\n",
    "from mask2former import add_maskformer2_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"data/smartphone_1.jpg\")\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(im[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "cfg.merge_from_file(\"Mask2Former/configs/coco/panoptic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_100ep.yaml\")\n",
    "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/maskformer/mask2former/coco/panoptic/maskformer2_swin_large_IN21k_384_bs16_100ep/model_final_f07440.pkl'\n",
    "cfg.MODEL.MASK_FORMER.TEST.SEMANTIC_ON = False\n",
    "cfg.MODEL.MASK_FORMER.TEST.INSTANCE_ON = True\n",
    "cfg.MODEL.MASK_FORMER.TEST.PANOPTIC_ON = True\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "instance_result = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\")).get_image()\n",
    "v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(instance_result[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = im.shape[0], im.shape[1]\n",
    "masks = outputs[\"instances\"].pred_masks.to(\"cpu\")\n",
    "pred_classes = outputs[\"instances\"].pred_classes.to(\"cpu\")\n",
    "n_channels = 4\n",
    "transparent_img = np.zeros((img_height, img_width, n_channels), dtype=np.uint8)\n",
    "phone_label_index = np.argmax(outputs[\"instances\"].scores.cpu().numpy())\n",
    "if (pred_classes[phone_label_index]==67):\n",
    "    for h in range(img_height):\n",
    "        for w in range(img_width):\n",
    "            #if(mask_1[h][w]==1):\n",
    "            if(masks[phone_label_index][h][w]==1):\n",
    "                transparent_img[h][w] = [im[h][w][0], im[h][w][1], im[h][w][2], 255]\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(transparent_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ccfd9746b7899ef0ee3df2fd5b69b50db817050fec3947d60a3b709ac4d89c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
